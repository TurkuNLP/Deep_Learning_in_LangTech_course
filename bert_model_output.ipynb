{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_model_output.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMC5auGeatFBjfpM4+ai3RW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/Deep_Learning_in_LangTech_course/blob/master/bert_model_output.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT\n"
      ],
      "metadata": {
        "id": "U2k3QEnj0hTN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuY096pr0DK_"
      },
      "outputs": [],
      "source": [
        "!pip3 install datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "tokenizer=transformers.AutoTokenizer.from_pretrained(\"bert-base-cased\") #you can also use the trusty \"TurkuNLP/bert-base-finnish-cased-v1\""
      ],
      "metadata": {
        "id": "SItSFN_-0sTU"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t=tokenizer([\"Dogs like to [MASK] cats.\"],return_tensors=\"pt\")\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3gKwiAf1Fg_",
        "outputId": "27644194-2676-4b21-ab28-9615f6404a17"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101, 16406,  1176,  1106,   103, 11771,   119,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(t[\"input_ids\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Hed6oOCO1Z1N",
        "outputId": "df96d3c9-b837-4751-b87a-d6bb10a8f6ae"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] Dogs like to [MASK] cats. [SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert=transformers.AutoModel.from_pretrained(\"bert-base-cased\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF6eNBzO16Fq",
        "outputId": "7e56adb9-22e9-4a61-dce1-08afa1a7fa9e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_out=bert(\n",
        "    input_ids=t[\"input_ids\"],\n",
        "    attention_mask=t[\"attention_mask\"],\n",
        "    token_type_ids=t[\"token_type_ids\"])\n",
        "#an easy way to say the above would be bert(**t)\n"
      ],
      "metadata": {
        "id": "KkunPLnt2QP0"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_out.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvGUp99n3e9x",
        "outputId": "c77373c7-517e-4c36-fe73-19f8bc6284a4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['last_hidden_state', 'pooler_output'])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_out.last_hidden_state.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlaUdarn3Yj7",
        "outputId": "b28a64b7-912d-4668-efc0-da1e1c88434f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_out.pooler_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIyI5ZfG3sBj",
        "outputId": "ab0ff649-e71d-46bb-f387-bfe1b34bb75d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert=transformers.AutoModelForPreTraining.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQy5gL0Z4VFW",
        "outputId": "f7bdfef7-c64a-4e88-adca-4cd497c2f3fb"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForPreTraining were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['cls.predictions.decoder.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert=bert.eval()"
      ],
      "metadata": {
        "id": "RAQmsa5b41sI"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_out=bert(**t)"
      ],
      "metadata": {
        "id": "HzHG0jn44-PL"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_out.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYEFMKuK5A8-",
        "outputId": "b399ddf7-b99b-49e3-bc88-63a33d856313"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['prediction_logits', 'seq_relationship_logits'])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_out.prediction_logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfHhGoe05G_a",
        "outputId": "1638dcc8-c70b-4edb-ae76-ea77abe6e909"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 28996])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8avjXIqT5L9W",
        "outputId": "9670f723-ff3f-4240-c18d-b19af1c8657c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28996"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "predictions=bert_out.prediction_logits\n",
        "am=torch.argmax(predictions,dim=2)\n",
        "tokenizer.decode(am[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hK95EH0F5Sl2",
        "outputId": "166f6a5f-10c9-407b-edd0-313aee65b612"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'.. like to eat cats..'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.argsort(predictions,dim=2,descending=True)[:,:,:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8lxob7T8sIL",
        "outputId": "4e02f90f-a016-4aa6-d9d8-682a8bc049bc"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[  119,   117,   107,  1103,   114,  1105,  1104,  1106,   136,  1116,\n",
              "            118,  1107,   170,   112,  1108,   113,   146,  1115,  1122,   188],\n",
              "         [  119,   107,   117,  1103,   114,  1104,   132,  1105,   136,  1106,\n",
              "            118,   112,   170,  1107,  1108,   113,   146,  1112,   188,  1116],\n",
              "         [ 1176,  1567,  3851,  3097,  4819,  1328,  5548,  6613,  9353,  1215,\n",
              "           1132, 20662,  1444,  7871,  1329,  2409,  7407,  2037,  3940,  1920],\n",
              "         [ 1106, 27629,  1152,  1122,  1103,  1128,  1195,  1136,  1105,   146,\n",
              "           1143,   170,  1115,  1172,   189,  1706,   117,  1184,  1315,  1198],\n",
              "         [ 3940,  1138, 11109,  9839,  2311,  1267,  8263,  1712,  2824, 13671,\n",
              "           1243,  1129,  1505,  2147,  1176,  3644,  4877,  3963, 19676,  1319],\n",
              "         [11771,  5855,  3551, 23463, 17408,  1172,  6363,  1122, 25164,  8892,\n",
              "           1234, 11260, 14986, 12237,  4067,  1128, 24488, 13475,  1143,  1152],\n",
              "         [  119,   132,   106,   136,  1232,   117,   131,   107,  1105,   118,\n",
              "           1128,   112,  1133,   197,  1272,  1141,  1106,  1115,   113,  1104],\n",
              "         [  119,   132,  1232,   136,   131,   106,   117,   107,  1105,   118,\n",
              "           1106,  1165,  1104,  1111,  1272,  1191,   120,  1112,   146,  1184]]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "o=torch.argsort(predictions,dim=2,descending=True)[:,:,:20]\n",
        "tokenizer.decode(o[0,4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aHsdKBuU9H-z",
        "outputId": "577089db-7209-4884-b395-979670b28620"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eat have pet chase kill see hunt keep watch scare get be play fight like avoid feed catch lick own'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    }
  ]
}