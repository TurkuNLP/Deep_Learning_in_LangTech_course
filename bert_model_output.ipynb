{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_model_output.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/Deep_Learning_in_LangTech_course/blob/master/bert_model_output.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic BERT operations\n"
      ],
      "metadata": {
        "id": "U2k3QEnj0hTN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "YuY096pr0DK_"
      },
      "outputs": [],
      "source": [
        "!pip3 -q install datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import datasets\n",
        "import torch"
      ],
      "metadata": {
        "id": "WMej7EPhAFRt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=transformers.AutoTokenizer.from_pretrained(\"bert-base-cased\") #you can also use the trusty \"TurkuNLP/bert-base-finnish-cased-v1\""
      ],
      "metadata": {
        "id": "SItSFN_-0sTU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will be running the model directly, so let's use return_tensors=\"pt\" to get torch tensors rather than Python lists\n",
        "texts=[\"Dogs like to [MASK] cats. They taste good.\",\"Bad joke!\"]\n",
        "t=tokenizer(texts,padding=True, truncation=True, return_tensors=\"pt\")\n",
        "print(\"Input ids\",t[\"input_ids\"])\n",
        "print(\"Token type ids\",t[\"token_type_ids\"])\n",
        "print(\"Attention mask\",t[\"attention_mask\"])"
      ],
      "metadata": {
        "id": "G3gKwiAf1Fg_",
        "outputId": "153bd45d-04d7-42c3-c6e1-f65967508e0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input ids tensor([[  101, 16406,  1176,  1106,   103, 11771,   119,  1220,  5080,  1363,\n",
            "           119,   102],\n",
            "        [  101,  6304,  8155,   106,   102,     0,     0,     0,     0,     0,\n",
            "             0,     0]])\n",
            "Token type ids tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "Attention mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is what the first sequence looks like\n",
        "tokenizer.decode(t[\"input_ids\"][0])"
      ],
      "metadata": {
        "id": "Hed6oOCO1Z1N",
        "outputId": "2e40a99a-94fe-4cd4-ffcc-86f9b6f0f318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] Dogs like to [MASK] cats. They taste good. [SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT: bare model\n",
        "* How to use the bare model\n",
        "* What does it give us?"
      ],
      "metadata": {
        "id": "tGout3eyB0qE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert=transformers.AutoModel.from_pretrained(\"bert-base-cased\") #\"TurkuNLP/bert-base-finnish-cased-v1\" if you run this in Finnish\n"
      ],
      "metadata": {
        "id": "dF6eNBzO16Fq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* in torch the model's forward() function tends to be mapped to `__call__()` i.e. it is used when you call the model as if it were a function\n"
      ],
      "metadata": {
        "id": "cfCp49YDCPlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_out=bert(\n",
        "    input_ids=t[\"input_ids\"],\n",
        "    attention_mask=t[\"attention_mask\"],\n",
        "    token_type_ids=t[\"token_type_ids\"])\n",
        "#an easy way to say the above would be bert(**t)\n"
      ],
      "metadata": {
        "id": "KkunPLnt2QP0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "that's it, this is how you call BERT, now let's see what it gave us (not hard to figure out it is really a dictionary)"
      ],
      "metadata": {
        "id": "w93TRT3rCloK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_out.keys()"
      ],
      "metadata": {
        "id": "CvGUp99n3e9x",
        "outputId": "0a66e990-c4ea-4025-f212-315cccb34622",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['last_hidden_state', 'pooler_output'])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* last_hidden_state: the last layer of the encoder\n",
        "* pooler_output: the `tanh` layer on top of `[CLS]`"
      ],
      "metadata": {
        "id": "m6X-qckrC1VM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before you run this, stop to think:\n",
        "# What will the shape be? How many dimensions? 1? 2? 3? more? And their approximate sizes?\n",
        "# make a guess, see if it matches\n",
        "bert_out.last_hidden_state.shape"
      ],
      "metadata": {
        "id": "vlaUdarn3Yj7",
        "outputId": "af485f46-e196-4d0f-e977-0b7c7d432ada",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 12, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# And here? What will the shape be?\n",
        "bert_out.pooler_output.shape"
      ],
      "metadata": {
        "id": "qIyI5ZfG3sBj",
        "outputId": "e2cbf641-48b6-453d-c003-4323c18313b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT: masked language modelling output\n",
        "\n",
        "* Not much we can do with the above\n",
        "* But BERT is trained to predict masked words, let's try!"
      ],
      "metadata": {
        "id": "AXhX93tbD2tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Have a look at HuggingFace automodels documentation to see what types of automodels there are\n",
        "bert=transformers.AutoModelForPreTraining.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "iQy5gL0Z4VFW"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tell the model it is not really being trained (disables dropout for example)\n",
        "# I do not think this is needed but am playing it safe, the docs say it is put to eval mode upon load: https://huggingface.co/docs/transformers/main_classes/model#transformers.PreTrainedModel.from_pretrained.config\n",
        "bert=bert.eval()"
      ],
      "metadata": {
        "id": "RAQmsa5b41sI"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can again run the model, and we will see the output is quite different!"
      ],
      "metadata": {
        "id": "LuFpVyBpFXjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_out=bert(**t)\n",
        "bert_out.keys()"
      ],
      "metadata": {
        "id": "HzHG0jn44-PL",
        "outputId": "82625cf4-e112-4224-b848-5c9d6cbe791a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['prediction_logits', 'seq_relationship_logits'])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What are these? https://huggingface.co/transformers/v3.0.2/model_doc/bert.html#transformers.BertForPreTraining\n",
        "#What do you think these shapes will be?\n",
        "print(\"Logits\",bert_out[\"prediction_logits\"].shape)\n",
        "print(\"Seq relationship logits\",bert_out[\"seq_relationship_logits\"].shape)"
      ],
      "metadata": {
        "id": "IYEFMKuK5A8-",
        "outputId": "5fb580fe-e5f3-4513-c142-3f0cf57389e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits torch.Size([2, 12, 28996])\n",
            "Seq relationship logits torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cross-check\n",
        "tokenizer.vocab_size"
      ],
      "metadata": {
        "id": "8avjXIqT5L9W",
        "outputId": "04339e5f-76f3-45e0-869f-0349bd768b2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28996"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "...now let's see how well this works for the masked word prediction...\n",
        "* we need to find the most likely predicted words\n",
        "* which can be achieved by arg-sorting the predictions and picking top N words\n",
        "* this is easy and we have done this kind of stuff before\n",
        "* now let's try straight in torch without a roundtrip to numpy"
      ],
      "metadata": {
        "id": "XtSGBan5QaXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = bert_out[\"prediction_logits\"]\n",
        "print(predictions.shape)\n",
        "top20=torch.argsort(predictions,dim=2,descending=True)[:,:,:20] #why dim=2? what does [:,:,:20] do?\n",
        "print(top20)"
      ],
      "metadata": {
        "id": "t8lxob7T8sIL",
        "outputId": "74a3b744-c7eb-450b-ccfd-952aa1669bda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 12, 28996])\n",
            "tensor([[[  119,   117,   107,   114,  1103,  1105,   136,  1104,  1106,   118,\n",
            "           1107,  1116,   170,   112,  1108,   113,   146,  1122,  1115,   188],\n",
            "         [  119,   107,   117,  1103,   132,   114,  1105,  1104,  1106,   136,\n",
            "            112,   118,   170,  1107,   146,  1108,   113,  1109,  1112,   188],\n",
            "         [ 1176,  1567,  3851,  4819,  1328,  9353,  2409,  6613,  5548,  3097,\n",
            "           2037,  3940,  1920, 13054,  1329,  1132,  7871, 20662,  1215,  7407],\n",
            "         [ 1106, 27629,  1128,  1152,  1103,  1195,   146,  1122,  1136,   170,\n",
            "           1115,  1706,  1105,  1143,   117,  1184,  6513,  1315,   189,  1505],\n",
            "         [ 3940,  9839,  1138, 11109,  1267,  8263,  2824,  2311, 13671,  1505,\n",
            "           1712,  1243,  4877,  4176,  1129,  2147, 19676,  1176,  3963,  3644],\n",
            "         [11771,  5855, 17408,  3551,  1172, 23463,  6363,  1122,  8892,  1234,\n",
            "          14986, 11260, 12237, 25164,  1128,  4067, 21235, 13475,  1152,   117],\n",
            "         [  119,   106,   132,  1232,   117,  1105,   136,   131,   118,  1272,\n",
            "            107,   112,  1133,  1191,  1163,  1177,  1176,  1165,  1115,  1106],\n",
            "         [ 1220, 17408, 16406,  2397,  1152,  1135,  1192,  1636, 16519,  1284,\n",
            "            146,  2563, 11771, 24989,  2695,  4435,  1789,  1124, 23420, 22143],\n",
            "         [ 5080,  4773,  3940, 18689,  1132,  1440,  9834,  2037,  1631,  3571,\n",
            "           1209,  1341,  1686, 12876,  4877,  4328, 27589,  9489,  1294,  5099],\n",
            "         [ 1363,  1632,  2213,  3505,  1618,  1218,  2503,  1176,  7310,  1344,\n",
            "           6548,  2012,  4105,  1992,  6866,  1436,  1612,  4489,  1957, 13108],\n",
            "         [  119,   132,   106,   136,  1232,   117,   131,   107,  1105,   118,\n",
            "            112,  1128,  1272,   197,  1141,  1116,   170,  1536,  3505,  1133],\n",
            "         [  119,   117,   136,   132,  1232,   131,   106,   107,  1105,  1106,\n",
            "           1111,   118,  1104,  1165,   146,  1191,  1315,  1272,  1126,  1115]],\n",
            "\n",
            "        [[  119,   117,   107,  1103,   114,  1105,  1104,   136,  1106,   118,\n",
            "           1107,  1116,   170,   112,  1108,  1140,  1123,   113,  1122,   188],\n",
            "         [  119,   107,   117,  1103,   114,   132,  1104,  1105,   136,  1106,\n",
            "            118,   112,   170,  1107,  1108,   146,   113,  1109,   188,   106],\n",
            "         [ 8155, 13948,  7959,  6276,  8594,  4046,  1911,  1128,  3789,  1159,\n",
            "          18114,  1122,  1162,  6920,  2629, 11079,  4928,  2176, 10219, 23027],\n",
            "         [  106,   136,   119,   132,  1232,   117,   197,   131,   118,  1110,\n",
            "           1105,   107,  1096,  1144,  1104,   635,  1170,   111,  1184,  1191],\n",
            "         [  119,   106,   136,  1232,   132,   118,   131,   117,   107,   197,\n",
            "            120,  1111,   114,  1105,   123,   122,   113,  1475,  1129,  2349],\n",
            "         [ 6304,   138,  1109,  2750,  2562,  6424,  1302,  3930,  2213, 25863,\n",
            "           2038,  2048,  1422,  2543,   118,   170, 14853, 25120,  8762,   119],\n",
            "         [  106,   136,  2048,  1302,  8762,  2160,   119,  2814, 25863,  1875,\n",
            "          11679, 16819,  8155, 11750,  1327, 12082,  7066, 27158,  1232, 12216],\n",
            "         [  106,   136,   119,   107,   112,   132,  1232,   118,   197,   117,\n",
            "            131,   114,   100,   198,   138,   166,  1105,   146,  1262,   115],\n",
            "         [  106,   107,   136,   119,   112,  1232,   118,   138,  1109,   132,\n",
            "            170,   100,  1262,   131,   197,  1105,  1302,   117,   115,  1252],\n",
            "         [  138,  6304,  1109,  6424,  1302,  2562,   118,  2750,  3930,   106,\n",
            "            119,   170,  2543,  1422, 25863,  2048,  1232,  2038,  1789,  1337],\n",
            "         [  138,   106,  6424,  1109,   119,   118,  2048,  1302,  6304,  1232,\n",
            "            136,  3930,  2562,  1422,   170,  1875, 25863,  1262,  1252,  8762],\n",
            "         [  106,   119,   136,  1232,   118,   107,   112,   138,  1109,   132,\n",
            "            117,  1105,  1262,  1137,  1252,   131,  1302,  2048,   170,  2926]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(texts[0])\n",
        "\n",
        "print(\"Guesses:\",tokenizer.decode(top20[0,4]))"
      ],
      "metadata": {
        "id": "aHsdKBuU9H-z",
        "outputId": "0ffc58bf-aea3-4ed2-9ce6-3d2a06ed8a80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dogs like to [MASK] cats. They taste good.\n",
            "Guesses: eat chase have pet see hunt watch kill scare play keep get feed ride be fight lick like catch avoid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ...in one block..."
      ],
      "metadata": {
        "id": "M0iadvxCSRNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts=[\"Dogs like to [MASK] cats. They are cute.\"]\n",
        "t=tokenizer(texts,padding=True, truncation=True, return_tensors=\"pt\")\n",
        "bert_out=bert(**t)\n",
        "top20=torch.argsort(bert_out[\"prediction_logits\"],dim=2,descending=True)[:,:,:20]\n",
        "print(\"Guesses:\",tokenizer.decode(top20[0,4]))"
      ],
      "metadata": {
        "id": "4XhmgLMgRubI",
        "outputId": "f360fc95-c0e0-488c-d31f-89e67a629c74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Guesses: have eat chase see pet keep play watch get scare be hunt ride like visit kill feed fight lick catch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t)\n",
        "print(tokenizer.mask_token_id)"
      ],
      "metadata": {
        "id": "Nmi_zDnsTKbP",
        "outputId": "8abae85d-32c8-4d86-f2c4-96cb2bcdbb8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101, 16406,  1176,  1106,   103, 11771,   119,  1220,  1132, 10509,\n",
            "           119,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASKS\n",
        "\n",
        "As an exercise, you can try to solve the following:\n",
        "\n",
        "1. How good is BERT at the masked language modelling (MLM) task? Feed random texts e.g. from the IMDB dataset, mask a random token at a time, and check: did BERT predict it correctly?\n",
        "2. If you did (1), can you answer did BERT predict it correctly in top-5?\n",
        "3. Try can you do better. Make yourself a program which picks random texts from one of the datasets we used in this course and produces two files: one with segments of texts with one [MASK] and one with the correct answers. Then try to guess the words without looking at the latter file and then compare your answers with the correct ones. How well did you do?\n"
      ],
      "metadata": {
        "id": "jZ3CmFs0VYed"
      }
    }
  ]
}