{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/Deep_Learning_in_LangTech_course/blob/master/gen_model_from_scratch/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04fb4c2a",
      "metadata": {
        "id": "04fb4c2a"
      },
      "source": [
        "Supporting code: https://github.com/TurkuNLP/Deep_Learning_in_LangTech_course/tree/master/gen_model_from_scratch\n",
        "\n",
        "\n",
        "Minimal training script for a tiny decoder-only (causal LM) model.\n",
        "\n",
        "- Uses a tokenizer saved by train_tokenizer.py (e.g., in fin_lemma.tokenizer)\n",
        "- Loads dataset JSON created by to_dataset.py with fields: {\"input\": ..., \"output\": ...}\n",
        "- Builds training sequences: <bos> INPUT <lemma> OUTPUT <eos>\n",
        "- Trains a very small model for demonstration purposes\n",
        "- Saves the trained model and tokenizer to output directory\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://dl.turkunlp.org/gen_model_from_scratch_data/dataset.json.gz\n",
        "!gzip -d dataset.json.gz\n",
        "!cat dataset.json | head -n 30"
      ],
      "metadata": {
        "id": "lxGfA7jzdQKj",
        "outputId": "4fe735d7-6661-4f69-ebc7-5f641e1e654e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lxGfA7jzdQKj",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-08 06:23:39--  http://dl.turkunlp.org/gen_model_from_scratch_data/dataset.json.gz\n",
            "Resolving dl.turkunlp.org (dl.turkunlp.org)... 195.148.30.23\n",
            "Connecting to dl.turkunlp.org (dl.turkunlp.org)|195.148.30.23|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1422218 (1.4M) [application/octet-stream]\n",
            "Saving to: ‘dataset.json.gz’\n",
            "\n",
            "dataset.json.gz     100%[===================>]   1.36M  1.18MB/s    in 1.2s    \n",
            "\n",
            "2025-10-08 06:23:40 (1.18 MB/s) - ‘dataset.json.gz’ saved [1422218/1422218]\n",
            "\n",
            "gzip: dataset.json already exists; do you wish to overwrite (y or n)? y\n",
            "[\n",
            "  {\n",
            "    \"input\": \"K ä v e l y r e i t t i NOUN Case=Nom Number=Sing\",\n",
            "    \"target\": \"k ä v e l y # r e i t t i\"\n",
            "  },\n",
            "  {\n",
            "    \"input\": \"I I I ADJ NumType=Ord\",\n",
            "    \"target\": \"I I I\"\n",
            "  },\n",
            "  {\n",
            "    \"input\": \"J ä ä l l ä NOUN Case=Ade Number=Sing\",\n",
            "    \"target\": \"j ä ä\"\n",
            "  },\n",
            "  {\n",
            "    \"input\": \"k ä v e l y NOUN Case=Nom Derivation=U Number=Sing\",\n",
            "    \"target\": \"k ä v e l y\"\n",
            "  },\n",
            "  {\n",
            "    \"input\": \"a v a a VERB Mood=Ind Number=Sing Person=3 Tense=Pres VerbForm=Fin Voice=Act\",\n",
            "    \"target\": \"a v a t a\"\n",
            "  },\n",
            "  {\n",
            "    \"input\": \"a i n a ADV\",\n",
            "    \"target\": \"a i n a\"\n",
            "  },\n",
            "  {\n",
            "    \"input\": \"h a u s k o j a ADJ Case=Par Degree=Pos Number=Plur\",\n",
            "    \"target\": \"h a u s k a\"\n",
            "  },\n",
            "  {\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://dl.turkunlp.org/gen_model_from_scratch_data/lemma_tokenizer.tgz\n",
        "!tar -xzf lemma_tokenizer.tgz"
      ],
      "metadata": {
        "id": "JPbFqKsjd268",
        "outputId": "9418791e-0b59-48ed-bdb4-65d004b4f1f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JPbFqKsjd268",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-08 06:23:54--  http://dl.turkunlp.org/gen_model_from_scratch_data/lemma_tokenizer.tgz\n",
            "Resolving dl.turkunlp.org (dl.turkunlp.org)... 195.148.30.23\n",
            "Connecting to dl.turkunlp.org (dl.turkunlp.org)|195.148.30.23|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2989 (2.9K) [application/octet-stream]\n",
            "Saving to: ‘lemma_tokenizer.tgz.1’\n",
            "\n",
            "lemma_tokenizer.tgz 100%[===================>]   2.92K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-08 06:23:55 (128 MB/s) - ‘lemma_tokenizer.tgz.1’ saved [2989/2989]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "86c5b8e2",
      "metadata": {
        "id": "86c5b8e2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import argparse\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "42c968ba",
      "metadata": {
        "id": "42c968ba"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from datasets import Dataset as HFDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "626b0c52",
      "metadata": {
        "id": "626b0c52"
      },
      "outputs": [],
      "source": [
        "import transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "7455ebde",
      "metadata": {
        "id": "7455ebde"
      },
      "outputs": [],
      "source": [
        "def create_tiny_gpt2_config(vocab_size):\n",
        "    \"\"\"Return a very small GPT-2 style config for quick CPU training.\n",
        "\n",
        "    Keep dimensions tiny to fit in memory and train quickly.\n",
        "    \"\"\"\n",
        "    return transformers.GPT2Config(\n",
        "        vocab_size=vocab_size,\n",
        "        n_positions=128,\n",
        "        n_ctx=128,\n",
        "        n_embd=128,\n",
        "        n_layer=2,\n",
        "        n_head=2,\n",
        "        bos_token_id=vocab_size - 2,  # will be overwritten by tokenizer mapping on resize\n",
        "        eos_token_id=vocab_size - 1,  # ditto; safe defaults\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a433615f",
      "metadata": {
        "id": "a433615f"
      },
      "outputs": [],
      "source": [
        "# Module-level parameters (friendly for Jupyter but not so great for production)\n",
        "tokenizer_dir = \"lemma.tokenizer\"\n",
        "data_path = \"dataset.json\"\n",
        "out_dir = \"fin_lemma.model\"\n",
        "block_size = 128\n",
        "batch_size = 16\n",
        "epochs = 15\n",
        "lr = 5e-4\n",
        "warmup_steps = 0\n",
        "weight_decay = 0.0\n",
        "seed = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "815085e5",
      "metadata": {
        "id": "815085e5"
      },
      "outputs": [],
      "source": [
        "# Make output directory\n",
        "os.makedirs(out_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e6e736d2",
      "metadata": {
        "id": "e6e736d2"
      },
      "outputs": [],
      "source": [
        "# Load tokenizer\n",
        "tokenizer = transformers.PreTrainedTokenizerFast.from_pretrained(tokenizer_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a8fd8521-1c57-4698-8163-676246c39cc5",
      "metadata": {
        "id": "a8fd8521-1c57-4698-8163-676246c39cc5",
        "outputId": "5f95eca1-e0f0-45a7-d928-0249e915a81f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'v ä k i v a l t a i s t e n ADJ Case=Gen Degree=Pos Derivation=Inen Number=Plur ::: v ä k i # v a l t a i n e n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "t=tokenizer(\"v ä k i v a l t a i s t e n ADJ Case=Gen Degree=Pos Derivation=Inen Number=Plur ::: v ä k i # v a l t a i n e n\")\n",
        "tokenizer.decode(t[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "4e904189",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "4e904189",
        "outputId": "7b75bdf5-59ae-4888-c874-41e3bb40a3a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "6d6031379341483b8de4cc38d48c6b63",
            "8334cdb9783e4859969c140c7e9c35b0",
            "bb76f1be637249579b718aac266f78d7",
            "45e602a9da214c17ac18ce28c0535623",
            "e3dd1ed9039a4cfe8b4049cb1d1714f6",
            "c2e521f6c0ee426aaa30fcde5546893f",
            "93272cdbdce641289403b35d51214df2",
            "e3c69174a3ea4d60a622b41728565a8c",
            "b707513b7ef04b0cb174e4f8118c6eb0",
            "368cb5487a6640238a3a8db17fe3f09d",
            "42aa60d2f06b4708916a8e0f12d71335"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d6031379341483b8de4cc38d48c6b63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train examples: 154674\n",
            "Eval examples: 8141\n"
          ]
        }
      ],
      "source": [
        "# Load dataset directly from JSON\n",
        "dataset = HFDataset.from_json(data_path)\n",
        "dataset = dataset.shuffle(seed=seed)\n",
        "dataset = dataset.train_test_split(test_size=0.05, seed=seed)\n",
        "train_dataset = dataset[\"train\"]\n",
        "eval_dataset = dataset[\"test\"]\n",
        "\n",
        "print(f\"Train examples: {len(train_dataset)}\")\n",
        "print(f\"Eval examples: {len(eval_dataset)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9dbd43fd",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "9dbd43fd"
      },
      "outputs": [],
      "source": [
        "# Build full sequences and tokenize using map\n",
        "def tokenize_function(example):\n",
        "    # Build full sequence: input + <lemma> + target + <eos>\n",
        "    text = f\"<bos> {example['input']} <lemma> {example['target']} <eos>\"\n",
        "    return tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=block_size,\n",
        "        padding=False,\n",
        "        return_tensors=None\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "84801ef1",
      "metadata": {
        "id": "84801ef1",
        "outputId": "89b8b9ff-af4e-41cd-976e-45a9cf395a42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "e1774ad34a2245b1a6adc76dca129483",
            "59dd938843f047e3b23e7eb6426b6a90",
            "0adf3ad782a9426093c014c468741aa0",
            "5435445d7d5c40c7ba6da2929dfd57e2",
            "11936e7fc79c4619a843483fa4226bf3",
            "f4a76a8321f845e4b84b985f02b49c28",
            "a85f69fe6c414cfa9d5153041a0e2a08",
            "d72a667e19cf45d4bac1d254776cd18e",
            "95dfe423b6dd444b8d2c252c8543a2e5",
            "aee3a8bf8c29480d849d57be703cf785",
            "e9d489751c1947f08495f5971d05cb3b",
            "c83353334b464a4cabcf9898b5ad5d80",
            "59271596596346deb5475b519d0b58f0",
            "27afbc58e7314ca4977ffe035f94bbeb",
            "8d0b0de9496c4f6cbc4a8b0ae674ad8d",
            "12d88ea620584a4b89b3ce12cc1d05b2",
            "0b98464e93674d25ba0959c7bd253604",
            "92672de7a19b45eda3f9b68e271e9ded",
            "6e88822d3e734a4facbb56fd23cf89be",
            "0ac464040e1443b7994f5a2556af92e7",
            "bb76e045038148c1b3a5f36c1907a64c",
            "60e10391dbc140909294cbb4992bf231"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/154674 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1774ad34a2245b1a6adc76dca129483"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/8141 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c83353334b464a4cabcf9898b5ad5d80"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Tokenize and drop original text columns to avoid collator string errors\n",
        "cols = dataset[\"train\"].column_names if hasattr(dataset, \"keys\") else dataset.column_names\n",
        "dataset = dataset.map(tokenize_function, remove_columns=cols)\n",
        "train_dataset = dataset[\"train\"]\n",
        "eval_dataset = dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b13241b3",
      "metadata": {
        "id": "b13241b3"
      },
      "outputs": [],
      "source": [
        "# Initialize tiny model\n",
        "config = create_tiny_gpt2_config(vocab_size=len(tokenizer))\n",
        "model = transformers.GPT2LMHeadModel(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "3165f14a",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "3165f14a"
      },
      "outputs": [],
      "source": [
        "# Training arguments\n",
        "training_args = transformers.TrainingArguments(\n",
        "    output_dir=out_dir,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    num_train_epochs=epochs,\n",
        "    learning_rate=lr,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    logging_steps=50,\n",
        "    save_steps=5000,\n",
        "    save_total_limit=1,\n",
        "    do_eval=True,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=5000,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    seed=seed,\n",
        "    report_to=[],  # disable W&B etc.\n",
        "    remove_unused_columns=True,\n",
        "    fp16=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "2a627521",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "2a627521"
      },
      "outputs": [],
      "source": [
        "# Data collator: mask input portion, train on target portion\n",
        "class DataCollatorForCompletionLM(transformers.DataCollatorForLanguageModeling):\n",
        "    def __init__(self, tokenizer, lemma_token_id):\n",
        "        super().__init__(tokenizer=tokenizer, mlm=False)\n",
        "        self.lemma_token_id = lemma_token_id\n",
        "\n",
        "    def __call__(self, features):\n",
        "        batch = super().__call__(features)\n",
        "        labels = batch[\"labels\"].clone()\n",
        "\n",
        "        # Mask everything before and including <lemma> token\n",
        "        for i, input_ids in enumerate(batch[\"input_ids\"]):\n",
        "            lemma_pos = (input_ids == self.lemma_token_id).nonzero(as_tuple=True)[0]\n",
        "            labels[i, :lemma_pos[0] + 1] = -100 #A magic number telling \"do not generate gradient from this output\"\n",
        "        batch[\"labels\"] = labels\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "e5b614f9",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "e5b614f9"
      },
      "outputs": [],
      "source": [
        "lemma_token_id = tokenizer.convert_tokens_to_ids(\"<lemma>\")\n",
        "data_collator = DataCollatorForCompletionLM(tokenizer, lemma_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "a52014d0",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "a52014d0"
      },
      "outputs": [],
      "source": [
        "# Callback: sample predictions every 5000 steps\n",
        "class EvalCallback(transformers.TrainerCallback):\n",
        "    def on_step_end(self, args, state, control, **kwargs):\n",
        "        if state.global_step % 5000 == 0 and state.global_step > 0:\n",
        "            print(f\"\\n=== Step {state.global_step} - Sample Predictions ===\")\n",
        "\n",
        "            # Pick 5 random eval examples\n",
        "            import random\n",
        "            indices = random.sample(range(len(eval_dataset)), min(5, len(eval_dataset)))\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for i, idx in enumerate(indices):\n",
        "                    example = eval_dataset[idx]\n",
        "                    input_ids = torch.tensor(example[\"input_ids\"]).unsqueeze(0).to(model.device)\n",
        "\n",
        "                    # Find <lemma> token position\n",
        "                    lemma_pos = (input_ids[0] == lemma_token_id).nonzero(as_tuple=True)[0]\n",
        "                    if len(lemma_pos) > 0:\n",
        "                        # Generate from <lemma> token onwards\n",
        "                        prompt = input_ids[:, :lemma_pos[0] + 1].to(model.device)\n",
        "\n",
        "                        generated = model.generate(\n",
        "                            prompt,\n",
        "                            max_new_tokens=50,\n",
        "                            do_sample=False,\n",
        "                            pad_token_id=tokenizer.pad_token_id,\n",
        "                            eos_token_id=tokenizer.eos_token_id\n",
        "                        )\n",
        "\n",
        "                        # Decode and print\n",
        "                        input_text = tokenizer.decode(input_ids[0], skip_special_tokens=False)\n",
        "                        generated_text = tokenizer.decode(generated[0], skip_special_tokens=False)\n",
        "\n",
        "                        print(f\"\\nExample {i+1}:\")\n",
        "                        print(f\"Input:  {input_text}\")\n",
        "                        print(f\"Output: {generated_text}\")\n",
        "\n",
        "            model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "39159cd8",
      "metadata": {
        "id": "39159cd8",
        "outputId": "f1974114-91be-48f5-e492-38e1d46211f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3864608145.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = transformers.Trainer(\n"
          ]
        }
      ],
      "source": [
        "# Assemble trainer\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    callbacks=[EvalCallback()]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "23bd4c41",
      "metadata": {
        "id": "23bd4c41",
        "outputId": "9e25c49a-3303-439e-b2c4-ed775c5fb5d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='108863' max='145020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [108863/145020 31:20 < 10:24, 57.88 it/s, Epoch 11.26/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.519200</td>\n",
              "      <td>0.345989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.435500</td>\n",
              "      <td>0.257085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.340500</td>\n",
              "      <td>0.215585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>0.284000</td>\n",
              "      <td>0.183967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25000</td>\n",
              "      <td>0.313100</td>\n",
              "      <td>0.164655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30000</td>\n",
              "      <td>0.227700</td>\n",
              "      <td>0.149185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35000</td>\n",
              "      <td>0.227900</td>\n",
              "      <td>0.145831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40000</td>\n",
              "      <td>0.212200</td>\n",
              "      <td>0.119727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45000</td>\n",
              "      <td>0.215900</td>\n",
              "      <td>0.112322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50000</td>\n",
              "      <td>0.173000</td>\n",
              "      <td>0.105888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55000</td>\n",
              "      <td>0.198100</td>\n",
              "      <td>0.102207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60000</td>\n",
              "      <td>0.194100</td>\n",
              "      <td>0.092016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65000</td>\n",
              "      <td>0.183400</td>\n",
              "      <td>0.087491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70000</td>\n",
              "      <td>0.152800</td>\n",
              "      <td>0.081401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75000</td>\n",
              "      <td>0.147100</td>\n",
              "      <td>0.075979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80000</td>\n",
              "      <td>0.179900</td>\n",
              "      <td>0.078138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85000</td>\n",
              "      <td>0.150900</td>\n",
              "      <td>0.073469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90000</td>\n",
              "      <td>0.137100</td>\n",
              "      <td>0.072121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95000</td>\n",
              "      <td>0.137600</td>\n",
              "      <td>0.065427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100000</td>\n",
              "      <td>0.115400</td>\n",
              "      <td>0.064779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105000</td>\n",
              "      <td>0.102400</td>\n",
              "      <td>0.063705</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Step 5000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> s u u n t a a n NOUN Case=Ill Number=Sing <lemma> s u u n t a <eos>\n",
            "Output: <bos> s u u n t a a n NOUN Case=Ill Number=Sing <lemma> s u u n t a <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> y k s i l ö k s i NOUN Case=Tra Number=Sing <lemma> y k s i l ö <eos>\n",
            "Output: <bos> y k s i l ö k s i NOUN Case=Tra Number=Sing <lemma> y k s i l ö <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> e i AUX Number=Sing Person=3 Polarity=Neg VerbForm=Fin Voice=Act <lemma> e i <eos>\n",
            "Output: <bos> e i AUX Number=Sing Person=3 Polarity=Neg VerbForm=Fin Voice=Act <lemma> e i <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> . PUNCT <lemma> . <eos>\n",
            "Output: <bos> . PUNCT <lemma> . <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> k u i n SCONJ <lemma> k u i n <eos>\n",
            "Output: <bos> k u i n SCONJ <lemma> k u i n <eos>\n",
            "\n",
            "=== Step 10000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> u u d e l t a ADJ Case=Abl Degree=Pos Number=Sing <lemma> u u s i <eos>\n",
            "Output: <bos> u u d e l t a ADJ Case=Abl Degree=Pos Number=Sing <lemma> u s i <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> p o i s s u l j e t t u VERB Case=Nom Number=Sing PartForm=Past VerbForm=Part Voice=Pass <lemma> p o i s s u l k e a <eos>\n",
            "Output: <bos> p o i s s u l j e t t u VERB Case=Nom Number=Sing PartForm=Past VerbForm=Part Voice=Pass <lemma> p o i s s s s t a a <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> m a a i l m a n s o t a NOUN Case=Nom Number=Sing <lemma> m a a i l m a n # s o t a <eos>\n",
            "Output: <bos> m a a i l m a n s o t a NOUN Case=Nom Number=Sing <lemma> m a i l l m a n t o <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> v a l t u u s k u n t a NOUN Case=Nom Number=Sing <lemma> v a l t u u s # k u n t a <eos>\n",
            "Output: <bos> v a l t u u s k u n t a NOUN Case=Nom Number=Sing <lemma> v a l t u s # k u n t u <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> s a a VERB Mood=Ind Number=Sing Person=3 Tense=Pres VerbForm=Fin Voice=Act <lemma> s a a d a <eos>\n",
            "Output: <bos> s a a VERB Mood=Ind Number=Sing Person=3 Tense=Pres VerbForm=Fin Voice=Act <lemma> s a a d a <eos>\n",
            "\n",
            "=== Step 15000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> t i l a s t o j e n NOUN Case=Gen Number=Plur <lemma> t i l a s t o <eos>\n",
            "Output: <bos> t i l a s t o j e n NOUN Case=Gen Number=Plur <lemma> t i l a s t o <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> h ä n e n PRON Case=Gen Number=Sing Person=3 PronType=Prs <lemma> h ä n <eos>\n",
            "Output: <bos> h ä n e n PRON Case=Gen Number=Sing Person=3 PronType=Prs <lemma> h ä n <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> N e l s o n PROPN Case=Nom Number=Sing <lemma> N e l s o n <eos>\n",
            "Output: <bos> N e l s o n PROPN Case=Nom Number=Sing <lemma> N e l s o n <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> 1 7 1 6 NUM NumType=Card <lemma> 1 7 1 6 <eos>\n",
            "Output: <bos> 1 7 1 6 NUM NumType=Card <lemma> 1 7 1 7 <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> k u u t e e n NUM Case=Ill Number=Sing NumType=Card <lemma> k u u s i <eos>\n",
            "Output: <bos> k u u t e e n NUM Case=Ill Number=Sing NumType=Card <lemma> k u u s i <eos>\n",
            "\n",
            "=== Step 20000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> l u e VERB Mood=Imp Number=Sing Person=2 VerbForm=Fin Voice=Act <lemma> l u k e a <eos>\n",
            "Output: <bos> l u e VERB Mood=Imp Number=Sing Person=2 VerbForm=Fin Voice=Act <lemma> l u k e a <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> j o t e n ADV <lemma> j o t e n <eos>\n",
            "Output: <bos> j o t e n ADV <lemma> j o t e n <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> ö l j y - y h t i ö n NOUN Case=Gen Number=Sing <lemma> ö l j y # y h t i ö <eos>\n",
            "Output: <bos> ö l j y - y h t i ö n NOUN Case=Gen Number=Sing <lemma> ö l j y # y h t i ö <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> n ä e n VERB Mood=Ind Number=Sing Person=1 Tense=Pres VerbForm=Fin Voice=Act <lemma> n ä h d ä <eos>\n",
            "Output: <bos> n ä e n VERB Mood=Ind Number=Sing Person=1 Tense=Pres VerbForm=Fin Voice=Act <lemma> n ä h d ä <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> s u k u a NOUN Case=Par Number=Sing <lemma> s u k u <eos>\n",
            "Output: <bos> s u k u a NOUN Case=Par Number=Sing <lemma> s u k u <eos>\n",
            "\n",
            "=== Step 25000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> j a CCONJ <lemma> j a <eos>\n",
            "Output: <bos> j a CCONJ <lemma> j a <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> j a CCONJ <lemma> j a <eos>\n",
            "Output: <bos> j a CCONJ <lemma> j a <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> K a i PROPN Case=Nom Number=Sing <lemma> K a i <eos>\n",
            "Output: <bos> K a i PROPN Case=Nom Number=Sing <lemma> K a i <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> j ä s e n v a l t i o t NOUN Case=Nom Number=Plur <lemma> j ä s e n # v a l t i o <eos>\n",
            "Output: <bos> j ä s e n v a l t i o t NOUN Case=Nom Number=Plur <lemma> j ä s e n # v a l t i o <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> j a CCONJ <lemma> j a <eos>\n",
            "Output: <bos> j a CCONJ <lemma> j a <eos>\n",
            "\n",
            "=== Step 30000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> k ä y t t ö NOUN Case=Nom Number=Sing <lemma> k ä y t t ö <eos>\n",
            "Output: <bos> k ä y t t ö NOUN Case=Nom Number=Sing <lemma> k ä y t t ö <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> E n k ä AUX Clitic=Ka Number=Sing Person=1 Polarity=Neg VerbForm=Fin Voice=Act <lemma> e i <eos>\n",
            "Output: <bos> E n k ä AUX Clitic=Ka Number=Sing Person=1 Polarity=Neg VerbForm=Fin Voice=Act <lemma> e i <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> H a n n a PROPN Case=Nom Number=Sing <lemma> H a n n a <eos>\n",
            "Output: <bos> H a n n a PROPN Case=Nom Number=Sing <lemma> H a n n a <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> p u u h u n NOUN Case=Ill Number=Sing <lemma> p u u <eos>\n",
            "Output: <bos> p u u h u n NOUN Case=Ill Number=Sing <lemma> p u u <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> m a h t u u VERB Mood=Ind Number=Sing Person=3 Tense=Pres VerbForm=Fin Voice=Act <lemma> m a h t u a <eos>\n",
            "Output: <bos> m a h t u u VERB Mood=Ind Number=Sing Person=3 Tense=Pres VerbForm=Fin Voice=Act <lemma> m a h t u a <eos>\n",
            "\n",
            "=== Step 35000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> K a n s a l l i s t e n ADJ Case=Gen Degree=Pos Derivation=Llinen Number=Plur <lemma> k a n s a l l i n e n <eos>\n",
            "Output: <bos> K a n s a l l i s t e n ADJ Case=Gen Degree=Pos Derivation=Llinen Number=Plur <lemma> k a n s a l l i n e n <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> k e s k e i s i ä ADJ Case=Par Degree=Pos Derivation=Inen Number=Plur <lemma> k e s k e i n e n <eos>\n",
            "Output: <bos> k e s k e i s i ä ADJ Case=Par Degree=Pos Derivation=Inen Number=Plur <lemma> k e s k e i n e n <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> 3 5 0 0 0 0 NUM NumType=Card <lemma> 3 5 0 0 0 0 <eos>\n",
            "Output: <bos> 3 5 0 0 0 0 NUM NumType=Card <lemma> 3 5 0 0 0 0 <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> k a l l e i m p i a ADJ Case=Par Degree=Sup Number=Plur <lemma> k a l l i s <eos>\n",
            "Output: <bos> k a l l e i m p i a ADJ Case=Par Degree=Sup Number=Plur <lemma> k a l l e a <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> t ä t ä PRON Case=Par Number=Sing PronType=Dem <lemma> t ä m ä <eos>\n",
            "Output: <bos> t ä t ä PRON Case=Par Number=Sing PronType=Dem <lemma> t ä m ä <eos>\n",
            "\n",
            "=== Step 40000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> v a s t a p a i n o k s i NOUN Case=Tra Number=Sing <lemma> v a s t a # p a i n o <eos>\n",
            "Output: <bos> v a s t a p a i n o k s i NOUN Case=Tra Number=Sing <lemma> v a s t a # p a i n t o <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> v u o r i NOUN Case=Nom Number=Sing <lemma> v u o r i <eos>\n",
            "Output: <bos> v u o r i NOUN Case=Nom Number=Sing <lemma> v u o r i <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> . PUNCT <lemma> . <eos>\n",
            "Output: <bos> . PUNCT <lemma> . <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> r i k k i p ä ä s t ö NOUN Case=Nom Number=Sing <lemma> r i k k i # p ä ä s t ö <eos>\n",
            "Output: <bos> r i k k i p ä ä s t ö NOUN Case=Nom Number=Sing <lemma> r i k k i # p ä ä s t ö <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> k u u n t e l e m a a n VERB Case=Ill InfForm=3 Number=Sing VerbForm=Inf Voice=Act <lemma> k u u n n e l l a <eos>\n",
            "Output: <bos> k u u n t e l e m a a n VERB Case=Ill InfForm=3 Number=Sing VerbForm=Inf Voice=Act <lemma> k u u u n n e l l a <eos>\n",
            "\n",
            "=== Step 45000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> j ä n n ä ADJ Case=Nom Degree=Pos Number=Sing <lemma> j ä n n ä <eos>\n",
            "Output: <bos> j ä n n ä ADJ Case=Nom Degree=Pos Number=Sing <lemma> j ä n ä <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> s o i t t a a VERB InfForm=1 Number=Sing VerbForm=Inf Voice=Act <lemma> s o i t t a a <eos>\n",
            "Output: <bos> s o i t t a a VERB InfForm=1 Number=Sing VerbForm=Inf Voice=Act <lemma> s o i t t a a <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> a i d a n NOUN Case=Gen Number=Sing <lemma> a i t a <eos>\n",
            "Output: <bos> a i d a n NOUN Case=Gen Number=Sing <lemma> a i t a <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> j o s SCONJ <lemma> j o s <eos>\n",
            "Output: <bos> j o s SCONJ <lemma> j o s <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> p i e n e s s ä ADJ Case=Ine Degree=Pos Number=Sing <lemma> p i e n i <eos>\n",
            "Output: <bos> p i e n e s s ä ADJ Case=Ine Degree=Pos Number=Sing <lemma> p i e n i <eos>\n",
            "\n",
            "=== Step 50000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> h u o m i o o n NOUN Case=Ill Number=Sing <lemma> h u o m i o <eos>\n",
            "Output: <bos> h u o m i o o n NOUN Case=Ill Number=Sing <lemma> h u o m i o <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> k e s ä m ö k k i a s u t u s t a NOUN Case=Par Number=Sing <lemma> k e s ä # m ö k k i # a s u t u s <eos>\n",
            "Output: <bos> k e s ä m ö k k i a s u t u s t a NOUN Case=Par Number=Sing <lemma> k e s ä # m a k k i s u t u s <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> e l i n t a r v i k e k e m i a n NOUN Case=Gen Number=Sing <lemma> e l i n # t a r v i k e # k e m i a <eos>\n",
            "Output: <bos> e l i n t a r v i k e k e m i a n NOUN Case=Gen Number=Sing <lemma> e l i n # t a r v i k e k e m a <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> p a i t s i ADV <lemma> p a i t s i <eos>\n",
            "Output: <bos> p a i t s i ADV <lemma> p a i t s i <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> h a n k a l a a ADJ Case=Par Degree=Pos Number=Sing <lemma> h a n k a l a <eos>\n",
            "Output: <bos> h a n k a l a a ADJ Case=Par Degree=Pos Number=Sing <lemma> h a n k a l a <eos>\n",
            "\n",
            "=== Step 55000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> v o i AUX Mood=Ind Number=Sing Person=3 Tense=Pres VerbForm=Fin Voice=Act <lemma> v o i d a <eos>\n",
            "Output: <bos> v o i AUX Mood=Ind Number=Sing Person=3 Tense=Pres VerbForm=Fin Voice=Act <lemma> v o i d a <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> j a CCONJ <lemma> j a <eos>\n",
            "Output: <bos> j a CCONJ <lemma> j a <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> t a l l i n NOUN Case=Gen Number=Sing <lemma> t a l l i <eos>\n",
            "Output: <bos> t a l l i n NOUN Case=Gen Number=Sing <lemma> t a l l i <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> t r e n d i NOUN Case=Nom Number=Sing <lemma> t r e n d i <eos>\n",
            "Output: <bos> t r e n d i NOUN Case=Nom Number=Sing <lemma> t r e n d i <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> , PUNCT <lemma> , <eos>\n",
            "Output: <bos> , PUNCT <lemma> , <eos>\n",
            "\n",
            "=== Step 60000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> . PUNCT <lemma> . <eos>\n",
            "Output: <bos> . PUNCT <lemma> . <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> G a r y PROPN Case=Nom Number=Sing <lemma> G a r y <eos>\n",
            "Output: <bos> G a r y PROPN Case=Nom Number=Sing <lemma> G a r y <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> E h k ä ADV <lemma> e h k ä <eos>\n",
            "Output: <bos> E h k ä ADV <lemma> e h k ä <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> p ö l ä h d y k s e n ä NOUN Case=Ess Number=Sing <lemma> p ö l ä h d y s <eos>\n",
            "Output: <bos> p ö l ä h d y k s e n ä NOUN Case=Ess Number=Sing <lemma> p ö l ä h d y s <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> h y v i n ADV <lemma> h y v i n <eos>\n",
            "Output: <bos> h y v i n ADV <lemma> h y v i n <eos>\n",
            "\n",
            "=== Step 65000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> k a n s a l l i s i a ADJ Case=Par Degree=Pos Derivation=Llinen Number=Plur <lemma> k a n s a l l i n e n <eos>\n",
            "Output: <bos> k a n s a l l i s i a ADJ Case=Par Degree=Pos Derivation=Llinen Number=Plur <lemma> k a n s a l l i n e n <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> k a n n a l t a NOUN Case=Abl Number=Sing <lemma> k a n t a <eos>\n",
            "Output: <bos> k a n n a l t a NOUN Case=Abl Number=Sing <lemma> k a n t a <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> + SYM <lemma> + <eos>\n",
            "Output: <bos> + SYM <lemma> + <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> , PUNCT <lemma> , <eos>\n",
            "Output: <bos> , PUNCT <lemma> , <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> v a i n ADV <lemma> v a i n <eos>\n",
            "Output: <bos> v a i n ADV <lemma> v a i n <eos>\n",
            "\n",
            "=== Step 70000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> F r a n ç o i s PROPN Case=Nom Number=Sing <lemma> F r a n ç o i s <eos>\n",
            "Output: <bos> F r a n ç o i s PROPN Case=Nom Number=Sing <lemma> F r a <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> s a l m o n e l l a - NOUN Case=Nom Number=Sing <lemma> s a l m o n e l l a <eos>\n",
            "Output: <bos> s a l m o n e l l a - NOUN Case=Nom Number=Sing <lemma> s a l m o n e l l a <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> | PUNCT <lemma> | <eos>\n",
            "Output: <bos> | PUNCT <lemma> | <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> p e l a a v a t VERB Mood=Ind Number=Plur Person=3 Tense=Pres VerbForm=Fin Voice=Act <lemma> p e l a t a <eos>\n",
            "Output: <bos> p e l a a v a t VERB Mood=Ind Number=Plur Person=3 Tense=Pres VerbForm=Fin Voice=Act <lemma> p e l a t a <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> t a l o u s k r i i s i t NOUN Case=Nom Number=Plur <lemma> t a l o u s # k r i i s i <eos>\n",
            "Output: <bos> t a l o u s k r i i s i t NOUN Case=Nom Number=Plur <lemma> t a l o u s # k i r i <eos>\n",
            "\n",
            "=== Step 75000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> j o ADV <lemma> j o <eos>\n",
            "Output: <bos> j o ADV <lemma> j o <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> o n AUX Mood=Ind Number=Sing Person=0 Tense=Pres VerbForm=Fin Voice=Act <lemma> o l l a <eos>\n",
            "Output: <bos> o n AUX Mood=Ind Number=Sing Person=0 Tense=Pres VerbForm=Fin Voice=Act <lemma> o l l a <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> k i i n n i ADV <lemma> k i i n n i <eos>\n",
            "Output: <bos> k i i n n i ADV <lemma> k i i n n i <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> t a i CCONJ <lemma> t a i <eos>\n",
            "Output: <bos> t a i CCONJ <lemma> t a i <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> p i i k k i k o r o i l l a NOUN Case=Ade Number=Plur <lemma> p i i k k i # k o r k o <eos>\n",
            "Output: <bos> p i i k k i k o r o i l l a NOUN Case=Ade Number=Plur <lemma> p i i k k i # k o r i <eos>\n",
            "\n",
            "=== Step 80000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> j a CCONJ <lemma> j a <eos>\n",
            "Output: <bos> j a CCONJ <lemma> j a <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> s a m a a n PRON Case=Ill Number=Sing PronType=Ind <lemma> s a m a <eos>\n",
            "Output: <bos> s a m a a n PRON Case=Ill Number=Sing PronType=Ind <lemma> s a m a <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> v ä l i l l ä ADP AdpType=Post <lemma> v ä l i l l ä <eos>\n",
            "Output: <bos> v ä l i l l ä ADP AdpType=Post <lemma> v ä l i l l ä <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> N ä t t i - U r p i PROPN Case=Nom Number=Sing <lemma> N ä t t i - U r p i <eos>\n",
            "Output: <bos> N ä t t i - U r p i PROPN Case=Nom Number=Sing <lemma> N ä t t i - U r k i <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> v e r k o s t o i t u m i s e e n NOUN Case=Ill Derivation=Minen Number=Sing <lemma> v e r k o s t o i t u m i n e n <eos>\n",
            "Output: <bos> v e r k o s t o i t u m i s e e n NOUN Case=Ill Derivation=Minen Number=Sing <lemma> v e r k o s t o i m u i n e n <eos>\n",
            "\n",
            "=== Step 85000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> j a CCONJ <lemma> j a <eos>\n",
            "Output: <bos> j a CCONJ <lemma> j a <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> r a t k a i s u j a NOUN Case=Par Derivation=U Number=Plur <lemma> r a t k a i s u <eos>\n",
            "Output: <bos> r a t k a i s u j a NOUN Case=Par Derivation=U Number=Plur <lemma> r a t k a i s u <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> L u e t t e l o NOUN Case=Nom Number=Sing <lemma> l u e t t e l o <eos>\n",
            "Output: <bos> L u e t t e l o NOUN Case=Nom Number=Sing <lemma> l u e t t e l o <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> v a a l e a n ADJ Case=Gen Degree=Pos Number=Sing <lemma> v a a l e a <eos>\n",
            "Output: <bos> v a a l e a n ADJ Case=Gen Degree=Pos Number=Sing <lemma> v a a l e a <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> k ä s i e n NOUN Case=Gen Number=Plur <lemma> k ä s i <eos>\n",
            "Output: <bos> k ä s i e n NOUN Case=Gen Number=Plur <lemma> k ä s i <eos>\n",
            "\n",
            "=== Step 90000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> l a u l u k i l p a i l u n NOUN Case=Gen Derivation=U Number=Sing <lemma> l a u l u # k i l p a i l u <eos>\n",
            "Output: <bos> l a u l u k i l p a i l u n NOUN Case=Gen Derivation=U Number=Sing <lemma> l a u l u # k i l p a i l u <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> , PUNCT <lemma> , <eos>\n",
            "Output: <bos> , PUNCT <lemma> , <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> k a n n a t u s NOUN Case=Nom Number=Sing <lemma> k a n n a t u s <eos>\n",
            "Output: <bos> k a n n a t u s NOUN Case=Nom Number=Sing <lemma> k a n n a t u s <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> J a p a n i i n PROPN Case=Ill Number=Sing <lemma> J a p a n i <eos>\n",
            "Output: <bos> J a p a n i i n PROPN Case=Ill Number=Sing <lemma> J a p a n <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> k o h t u u l l i s e l l a ADJ Case=Ade Degree=Pos Derivation=Llinen Number=Sing <lemma> k o h t u u l l i n e n <eos>\n",
            "Output: <bos> k o h t u u l l i s e l l a ADJ Case=Ade Degree=Pos Derivation=Llinen Number=Sing <lemma> k o h t u u l l i n e n <eos>\n",
            "\n",
            "=== Step 95000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> . PUNCT <lemma> . <eos>\n",
            "Output: <bos> . PUNCT <lemma> . <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> . PUNCT <lemma> . <eos>\n",
            "Output: <bos> . PUNCT <lemma> . <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> h u o n o s t a ADJ Case=Ela Degree=Pos Number=Sing <lemma> h u o n o <eos>\n",
            "Output: <bos> h u o n o s t a ADJ Case=Ela Degree=Pos Number=Sing <lemma> h u o n o <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> e t t ä SCONJ <lemma> e t t ä <eos>\n",
            "Output: <bos> e t t ä SCONJ <lemma> e t t ä <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> p e r u s k a a v a NOUN Case=Nom Number=Sing <lemma> p e r u s # k a a v a <eos>\n",
            "Output: <bos> p e r u s k a a v a NOUN Case=Nom Number=Sing <lemma> p e r u s # k a a v a <eos>\n",
            "\n",
            "=== Step 100000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> U u t e e n - S e e l a n t i i n PROPN Case=Ill Number=Sing <lemma> U u s i - S e e l a n t i <eos>\n",
            "Output: <bos> U u t e e n - S e e l a n t i i n PROPN Case=Ill Number=Sing <lemma> U u t e e n - S e l a n t i <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> p ä ä u u t i s e t NOUN Case=Nom Number=Plur <lemma> p ä ä # u u t i n e n <eos>\n",
            "Output: <bos> p ä ä u u t i s e t NOUN Case=Nom Number=Plur <lemma> p ä ä u u t i n e n <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> i d y l l i s t e n ADJ Case=Gen Degree=Pos Derivation=Llinen Number=Plur <lemma> i d y l l i n e n <eos>\n",
            "Output: <bos> i d y l l i s t e n ADJ Case=Gen Degree=Pos Derivation=Llinen Number=Plur <lemma> i d y l l i n e n <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> p u u s k u t t a e s s a VERB Case=Ine InfForm=2 Number=Sing VerbForm=Inf Voice=Act <lemma> p u u s k u t t a a <eos>\n",
            "Output: <bos> p u u s k u t t a e s s a VERB Case=Ine InfForm=2 Number=Sing VerbForm=Inf Voice=Act <lemma> p u u s k u t t a a <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> K e v y t ADJ Case=Nom Degree=Pos Number=Sing <lemma> k e v y t <eos>\n",
            "Output: <bos> K e v y t ADJ Case=Nom Degree=Pos Number=Sing <lemma> k e v y t <eos>\n",
            "\n",
            "=== Step 105000 - Sample Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Input:  <bos> . PUNCT <lemma> . <eos>\n",
            "Output: <bos> . PUNCT <lemma> . <eos>\n",
            "\n",
            "Example 2:\n",
            "Input:  <bos> o l e v i e n VERB Case=Gen Number=Plur PartForm=Pres VerbForm=Part Voice=Act <lemma> o l l a <eos>\n",
            "Output: <bos> o l e v i e n VERB Case=Gen Number=Plur PartForm=Pres VerbForm=Part Voice=Act <lemma> o l l a <eos>\n",
            "\n",
            "Example 3:\n",
            "Input:  <bos> * PUNCT <lemma> * <eos>\n",
            "Output: <bos> * PUNCT <lemma> * <eos>\n",
            "\n",
            "Example 4:\n",
            "Input:  <bos> . PUNCT <lemma> . <eos>\n",
            "Output: <bos> . PUNCT <lemma> . <eos>\n",
            "\n",
            "Example 5:\n",
            "Input:  <bos> M a n n e r h e i m - r i s t i NOUN Case=Nom Number=Sing <lemma> M a n n e r h e i m # r i s t i <eos>\n",
            "Output: <bos> M a n n e r h e i m - r i s t i NOUN Case=Nom Number=Sing <lemma> m a n n e r h e i m # r i s t i <eos>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4032216753.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2326\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2328\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2329\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2670\u001b[0m                     )\n\u001b[1;32m   2671\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2672\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m                     if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4058\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scale_wrt_gas\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4060\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4062\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2732\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2733\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2734\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2736\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2af4676",
      "metadata": {
        "id": "f2af4676"
      },
      "outputs": [],
      "source": [
        "# Save artifacts\n",
        "trainer.save_model(out_dir)\n",
        "tokenizer.save_pretrained(out_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38004165",
      "metadata": {
        "id": "38004165"
      },
      "outputs": [],
      "source": [
        "print(f\"Model and tokenizer saved to: {out_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3e5bba6-b3b1-47df-ae4f-da8a3147475e",
      "metadata": {
        "id": "d3e5bba6-b3b1-47df-ae4f-da8a3147475e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6d6031379341483b8de4cc38d48c6b63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8334cdb9783e4859969c140c7e9c35b0",
              "IPY_MODEL_bb76f1be637249579b718aac266f78d7",
              "IPY_MODEL_45e602a9da214c17ac18ce28c0535623"
            ],
            "layout": "IPY_MODEL_e3dd1ed9039a4cfe8b4049cb1d1714f6"
          }
        },
        "8334cdb9783e4859969c140c7e9c35b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2e521f6c0ee426aaa30fcde5546893f",
            "placeholder": "​",
            "style": "IPY_MODEL_93272cdbdce641289403b35d51214df2",
            "value": "Generating train split: "
          }
        },
        "bb76f1be637249579b718aac266f78d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3c69174a3ea4d60a622b41728565a8c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b707513b7ef04b0cb174e4f8118c6eb0",
            "value": 1
          }
        },
        "45e602a9da214c17ac18ce28c0535623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_368cb5487a6640238a3a8db17fe3f09d",
            "placeholder": "​",
            "style": "IPY_MODEL_42aa60d2f06b4708916a8e0f12d71335",
            "value": " 162815/0 [00:00&lt;00:00, 330007.12 examples/s]"
          }
        },
        "e3dd1ed9039a4cfe8b4049cb1d1714f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2e521f6c0ee426aaa30fcde5546893f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93272cdbdce641289403b35d51214df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3c69174a3ea4d60a622b41728565a8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b707513b7ef04b0cb174e4f8118c6eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "368cb5487a6640238a3a8db17fe3f09d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42aa60d2f06b4708916a8e0f12d71335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1774ad34a2245b1a6adc76dca129483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59dd938843f047e3b23e7eb6426b6a90",
              "IPY_MODEL_0adf3ad782a9426093c014c468741aa0",
              "IPY_MODEL_5435445d7d5c40c7ba6da2929dfd57e2"
            ],
            "layout": "IPY_MODEL_11936e7fc79c4619a843483fa4226bf3"
          }
        },
        "59dd938843f047e3b23e7eb6426b6a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4a76a8321f845e4b84b985f02b49c28",
            "placeholder": "​",
            "style": "IPY_MODEL_a85f69fe6c414cfa9d5153041a0e2a08",
            "value": "Map: 100%"
          }
        },
        "0adf3ad782a9426093c014c468741aa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d72a667e19cf45d4bac1d254776cd18e",
            "max": 154674,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95dfe423b6dd444b8d2c252c8543a2e5",
            "value": 154674
          }
        },
        "5435445d7d5c40c7ba6da2929dfd57e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aee3a8bf8c29480d849d57be703cf785",
            "placeholder": "​",
            "style": "IPY_MODEL_e9d489751c1947f08495f5971d05cb3b",
            "value": " 154674/154674 [00:34&lt;00:00, 3907.93 examples/s]"
          }
        },
        "11936e7fc79c4619a843483fa4226bf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4a76a8321f845e4b84b985f02b49c28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a85f69fe6c414cfa9d5153041a0e2a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d72a667e19cf45d4bac1d254776cd18e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95dfe423b6dd444b8d2c252c8543a2e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aee3a8bf8c29480d849d57be703cf785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9d489751c1947f08495f5971d05cb3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c83353334b464a4cabcf9898b5ad5d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59271596596346deb5475b519d0b58f0",
              "IPY_MODEL_27afbc58e7314ca4977ffe035f94bbeb",
              "IPY_MODEL_8d0b0de9496c4f6cbc4a8b0ae674ad8d"
            ],
            "layout": "IPY_MODEL_12d88ea620584a4b89b3ce12cc1d05b2"
          }
        },
        "59271596596346deb5475b519d0b58f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b98464e93674d25ba0959c7bd253604",
            "placeholder": "​",
            "style": "IPY_MODEL_92672de7a19b45eda3f9b68e271e9ded",
            "value": "Map: 100%"
          }
        },
        "27afbc58e7314ca4977ffe035f94bbeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e88822d3e734a4facbb56fd23cf89be",
            "max": 8141,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ac464040e1443b7994f5a2556af92e7",
            "value": 8141
          }
        },
        "8d0b0de9496c4f6cbc4a8b0ae674ad8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb76e045038148c1b3a5f36c1907a64c",
            "placeholder": "​",
            "style": "IPY_MODEL_60e10391dbc140909294cbb4992bf231",
            "value": " 8141/8141 [00:01&lt;00:00, 4559.85 examples/s]"
          }
        },
        "12d88ea620584a4b89b3ce12cc1d05b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b98464e93674d25ba0959c7bd253604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92672de7a19b45eda3f9b68e271e9ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e88822d3e734a4facbb56fd23cf89be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ac464040e1443b7994f5a2556af92e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb76e045038148c1b3a5f36c1907a64c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60e10391dbc140909294cbb4992bf231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}