{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f16d689c43f4761ae3c57093883c282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d060ee7d33f455b9982ce5c56edbdba",
              "IPY_MODEL_c6129dbf4016487e979f02fefff325ad",
              "IPY_MODEL_aa0728e0ac154ae7b90955a62426eedc"
            ],
            "layout": "IPY_MODEL_5d7b1f95406944d8b71431835d571be3"
          }
        },
        "1d060ee7d33f455b9982ce5c56edbdba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab10683f380142b3a57830568e7eff83",
            "placeholder": "​",
            "style": "IPY_MODEL_faf3f0fca5a642a6a3c712a1ab008980",
            "value": "Map: 100%"
          }
        },
        "c6129dbf4016487e979f02fefff325ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81ade7bd547d4008b96cf8c7f83700d8",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d73c7e84504143c8a9b2c4293321e27e",
            "value": 100
          }
        },
        "aa0728e0ac154ae7b90955a62426eedc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1b6300e73ba464d9f4699bf6c921545",
            "placeholder": "​",
            "style": "IPY_MODEL_7319c406740547a79493fa5cc571429a",
            "value": " 100/100 [00:00&lt;00:00, 993.60 examples/s]"
          }
        },
        "5d7b1f95406944d8b71431835d571be3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab10683f380142b3a57830568e7eff83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faf3f0fca5a642a6a3c712a1ab008980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81ade7bd547d4008b96cf8c7f83700d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d73c7e84504143c8a9b2c4293321e27e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1b6300e73ba464d9f4699bf6c921545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7319c406740547a79493fa5cc571429a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/Deep_Learning_in_LangTech_course/blob/master/masked_language_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT for masked langauge modelling\n"
      ],
      "metadata": {
        "id": "U2k3QEnj0hTN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YuY096pr0DK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8722ef1-9cee-4a94-e3eb-831ac6117f5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip3 -q install datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import datasets\n",
        "import torch"
      ],
      "metadata": {
        "id": "WMej7EPhAFRt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT: masked language modelling output\n",
        "\n",
        "* But BERT is trained to predict masked words, let's try!"
      ],
      "metadata": {
        "id": "AXhX93tbD2tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-cased\") #you can also use the trusty \"TurkuNLP/bert-base-finnish-cased-v1\"\n",
        "bert = transformers.AutoModelForPreTraining.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "iQy5gL0Z4VFW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tell the model it is not really being trained (disables dropout for example)\n",
        "# I do not think this is needed but am playing it safe, the docs say it is put to eval mode upon load: https://huggingface.co/docs/transformers/main_classes/model#transformers.PreTrainedModel.from_pretrained.config\n",
        "bert = bert.eval()"
      ],
      "metadata": {
        "id": "RAQmsa5b41sI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...now let's see how well this works for the masked word prediction...\n",
        "* we need to find the most likely predicted words\n",
        "* which can be achieved by arg-sorting the predictions and picking top N words\n",
        "* this is easy and we have done this kind of stuff before\n",
        "* now let's try straight in torch without a roundtrip to numpy"
      ],
      "metadata": {
        "id": "XtSGBan5QaXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\"Dogs like to [MASK] cats. They are cute.\"]\n",
        "\n",
        "t = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "bert_out = bert(**t)\n",
        "top20 = torch.argsort(bert_out[\"prediction_logits\"], dim=2, descending=True)[:,:,:20]\n",
        "\n",
        "print(\"Guesses:\",tokenizer.decode(top20[0,4]))"
      ],
      "metadata": {
        "id": "4XhmgLMgRubI",
        "outputId": "a361d540-18db-42cd-b35a-0a399a13d061",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Guesses: have eat chase see pet keep play watch get scare be hunt ride like visit kill feed fight lick catch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t)\n",
        "print(tokenizer.mask_token_id)"
      ],
      "metadata": {
        "id": "Nmi_zDnsTKbP",
        "outputId": "887695de-3cb5-44b3-8bae-687d0e051504",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101, 16406,  1176,  1106,   103, 11771,   119,  1220,  1132, 10509,\n",
            "           119,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASKS\n",
        "\n",
        "As an exercise, you can try to solve the following:\n",
        "\n",
        "1. How good is BERT at the masked language modelling (MLM) task? Feed random texts e.g. from the IMDB dataset, mask a random token at a time, and check: did BERT predict it correctly?\n",
        "2. If you did (1), can you answer did BERT predict it correctly in top-5?\n",
        "3. Try can you do better. Make yourself a program which picks random texts from one of the datasets we used in this course and produces two files: one with segments of texts with one [MASK] and one with the correct answers. Then try to guess the words without looking at the latter file and then compare your answers with the correct ones. How well did you do?\n"
      ],
      "metadata": {
        "id": "jZ3CmFs0VYed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General notes:\n",
        "\n",
        "* Some of you had problems (or really bad performance) because you failed to select predictions for the correct token\n",
        "* In the example code, the index of the masked token was hard-coded: **top20[0,4]**\n",
        "* A typical error was to manually select the index based on the original text, not the tokenized text\n",
        "  - _Dogs like to [MASK] cats. They are cute._ --> fourth token, so index=3\n",
        "  - _[CLS] Dogs like to [MASK] cats . They are cute . [SEP]_ --> fifth token, so index=4\n",
        "  - Note that tokenizer can also split tokens into subwords, so cannot assume just +1 for inserted CLS!\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RzkwxZNaaAvs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8EFv26BOFvXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(tokenizer))\n",
        "text = \"Dogs like to [MASK] cats. They are cute.\"\n",
        "tok = tokenizer(texts[0])\n",
        "print(tok)\n",
        "detok = tokenizer.convert_ids_to_tokens(tok[\"input_ids\"])\n",
        "print(detok)\n",
        "print(detok[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TKO67bAZ-m_",
        "outputId": "1384d177-af17-4d15-cbb4-01fa2bd674c9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['SPECIAL_TOKENS_ATTRIBUTES', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_add_tokens', '_additional_special_tokens', '_auto_class', '_batch_encode_plus', '_bos_token', '_call_one', '_cls_token', '_convert_encoding', '_convert_id_to_token', '_convert_token_to_id_with_added_voc', '_create_repo', '_decode', '_decode_use_source_tokenizer', '_encode_plus', '_eos_token', '_eventual_warn_about_too_long_sequence', '_eventually_correct_t5_max_length', '_from_pretrained', '_get_files_timestamps', '_get_padding_truncation_strategies', '_in_target_context_manager', '_mask_token', '_pad', '_pad_token', '_pad_token_type_id', '_processor_class', '_save_pretrained', '_sep_token', '_set_processor_class', '_switch_to_input_mode', '_switch_to_target_mode', '_tokenizer', '_unk_token', '_upload_modified_files', 'add_special_tokens', 'add_tokens', 'additional_special_tokens', 'additional_special_tokens_ids', 'all_special_ids', 'all_special_tokens', 'all_special_tokens_extended', 'as_target_tokenizer', 'backend_tokenizer', 'batch_decode', 'batch_encode_plus', 'bos_token', 'bos_token_id', 'build_inputs_with_special_tokens', 'can_save_slow_tokenizer', 'clean_up_tokenization', 'clean_up_tokenization_spaces', 'cls_token', 'cls_token_id', 'convert_ids_to_tokens', 'convert_tokens_to_ids', 'convert_tokens_to_string', 'create_token_type_ids_from_sequences', 'decode', 'decoder', 'deprecation_warnings', 'do_lower_case', 'encode', 'encode_plus', 'eos_token', 'eos_token_id', 'from_pretrained', 'get_added_vocab', 'get_special_tokens_mask', 'get_vocab', 'init_inputs', 'init_kwargs', 'is_fast', 'mask_token', 'mask_token_id', 'max_len_sentences_pair', 'max_len_single_sentence', 'max_model_input_sizes', 'model_input_names', 'model_max_length', 'name_or_path', 'num_special_tokens_to_add', 'pad', 'pad_token', 'pad_token_id', 'pad_token_type_id', 'padding_side', 'prepare_for_model', 'prepare_seq2seq_batch', 'pretrained_init_configuration', 'pretrained_vocab_files_map', 'push_to_hub', 'register_for_auto_class', 'sanitize_special_tokens', 'save_pretrained', 'save_vocabulary', 'sep_token', 'sep_token_id', 'set_truncation_and_padding', 'slow_tokenizer_class', 'special_tokens_map', 'special_tokens_map_extended', 'split_special_tokens', 'tokenize', 'train_new_from_iterator', 'truncate_sequences', 'truncation_side', 'unk_token', 'unk_token_id', 'verbose', 'vocab', 'vocab_files_names', 'vocab_size']\n",
            "{'input_ids': [101, 16406, 1176, 1106, 103, 11771, 119, 1220, 1132, 10509, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "['[CLS]', 'Dogs', 'like', 'to', '[MASK]', 'cats', '.', 'They', 'are', 'cute', '.', '[SEP]']\n",
            "[MASK]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"DOGS LIKE TO [MASK] CATS. THEY ARE CUTE.\"\n",
        "tok = tokenizer(text)\n",
        "print(tok)\n",
        "detok = tokenizer.convert_ids_to_tokens(tok[\"input_ids\"])\n",
        "print(detok)\n",
        "print(detok[8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdVn-2cqe39w",
        "outputId": "0b7fe975-598c-4c6f-de38-be1a3bab4197"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 141, 2346, 13472, 149, 2240, 22441, 16972, 103, 8784, 11365, 119, 7462, 3663, 22133, 2036, 140, 16830, 2036, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "['[CLS]', 'D', '##O', '##GS', 'L', '##I', '##KE', 'TO', '[MASK]', 'CA', '##TS', '.', 'THE', '##Y', 'AR', '##E', 'C', '##UT', '##E', '.', '[SEP]']\n",
            "[MASK]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Genaralize to mask a random token and get predictions for it"
      ],
      "metadata": {
        "id": "r2G-iLw3gcIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get some data\n",
        "dataset = datasets.load_dataset(\"imdb\", split=\"train\") # we need only training section\n",
        "dataset = dataset.shuffle()\n",
        "dataset = dataset.select(range(100)) # downsample\n",
        "print(dataset)\n",
        "print(dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPH4ce-ygnx8",
        "outputId": "a3c152ca-0bf0-4f30-9ed1-083aacf58e1c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 100\n",
            "})\n",
            "{'text': 'I rented this movie because it sounded pretty interesting but to my Horror this movie was the worst movie I had ever seen! I read the comment from Gumby-8 and he has to be a part of the cast or the crew. Unless Gumby-8 is a 4 year old child or some demented cult member no one in their right mind would think that this movie had any potential at all.<br /><br />I couldn\\'t believe Gumby-8\\'s comments. <br /><br />Quoting: \"From the \"Dune\" inspired opening animation to the quick pace...this film keeps the eye moving and works so well that repeat viewing is not unexpected.\"<br /><br />The Animation is the only aspect of the movie that was interesting and the fact of that the film keeps the eye moving, well that\\'s because you keep looking for any type of suspense. I mean give me a break Halloween was shot with a budget of $100,000.00 and a painted mask and also by the way became a cult classic. As far as \"repeat viewing is not unexpected\" I think he made a typo.<br /><br />Another quote from Gumby-8 the only Fan: \"The acting is also a strong aspect of the film.\"<br /><br />With all due respect for the actors, their performance is nothing more than the respective talent of Robert Napton.<br /><br />The catchy Tagline: \"Beware the hour between dusk and darkness\"<br /><br />That\\'s because there is no dusk or darkness in this movie.<br /><br />MPAA rating \"Rated R for some violence/gore\"<br /><br />The only gore you see is some red paint on a sheet over a dead body you never see. As far as I know it might be a clump of grass.<br /><br />In summation, I have seen horror flicks from the 50\\'s, 60\\'s and 70\\'s. I have seen what I thought to be the absolutely worst and some that were very good. The director of this film either did not make any attempt, was asleep, or took a hit of acid. Whatever the case I think the actors deserve applause for trying to salvage a very poor job of direction. I would give this film a rating of .5 for a \\'B\\' movie.', 'label': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# truncate review texts to make it easier to spot things, this step is not necessary!\n",
        "# Note that this can make the task easier / more difficult compared to full reviews\n",
        "\n",
        "def truncate_review(example):\n",
        "  text = example[\"text\"]\n",
        "  tokens = text.split() # naive tokenization, split on whitespace\n",
        "  tokens = tokens[:30] # let's keep first 30 tokens\n",
        "  short_text = \" \".join(tokens) # convert back to string\n",
        "  return {\"text\": short_text}\n",
        "\n",
        "dataset = dataset.map(truncate_review)\n",
        "print(dataset)\n",
        "print(dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "2f16d689c43f4761ae3c57093883c282",
            "1d060ee7d33f455b9982ce5c56edbdba",
            "c6129dbf4016487e979f02fefff325ad",
            "aa0728e0ac154ae7b90955a62426eedc",
            "5d7b1f95406944d8b71431835d571be3",
            "ab10683f380142b3a57830568e7eff83",
            "faf3f0fca5a642a6a3c712a1ab008980",
            "81ade7bd547d4008b96cf8c7f83700d8",
            "d73c7e84504143c8a9b2c4293321e27e",
            "a1b6300e73ba464d9f4699bf6c921545",
            "7319c406740547a79493fa5cc571429a"
          ]
        },
        "id": "wemeT4xTjmuQ",
        "outputId": "673b9e31-40d2-4d43-8d56-f5ef74f50694"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f16d689c43f4761ae3c57093883c282"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 100\n",
            "})\n",
            "{'text': 'I rented this movie because it sounded pretty interesting but to my Horror this movie was the worst movie I had ever seen! I read the comment from Gumby-8 and', 'label': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's test how masking of a random token works\n",
        "\n",
        "import random\n",
        "\n",
        "#help(tokenizer.decode)\n",
        "\n",
        "text = dataset[0][\"text\"]\n",
        "\n",
        "t = tokenizer(text) # prepare normal tokenized input\n",
        "print(\"input_ids:\", t[\"input_ids\"])\n",
        "print(\"tokens:\", tokenizer.decode(t[\"input_ids\"]))\n",
        "\n",
        "random_idx = random.randint(1, len(t[\"input_ids\"])-2) # sample random token, -2 so that we do not mask the last token which is [SEP]\n",
        "print(\"random index:\", random_idx, tokenizer.decode(t[\"input_ids\"][random_idx]))\n",
        "\n",
        "t[\"input_ids\"][random_idx] = tokenizer.mask_token_id # mask the token in input\n",
        "print(\"masked tokens:\", tokenizer.decode(t[\"input_ids\"]))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkPCYNVHhw9O",
        "outputId": "a9f7d1e0-71e3-40fe-b151-8392606ab36b"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids: [101, 146, 12765, 1142, 2523, 1272, 1122, 4234, 2785, 5426, 1133, 1106, 1139, 16709, 1142, 2523, 1108, 1103, 4997, 2523, 146, 1125, 1518, 1562, 106, 146, 2373, 1103, 7368, 1121, 144, 1818, 2665, 118, 129, 1105, 102]\n",
            "tokens: [CLS] I rented this movie because it sounded pretty interesting but to my Horror this movie was the worst movie I had ever seen! I read the comment from Gumby - 8 and [SEP]\n",
            "random index: 4 movie\n",
            "masked tokens: [CLS] I rented this [MASK] because it sounded pretty interesting but to my Horror this movie was the worst movie I had ever seen! I read the comment from Gumby - 8 and [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define function to tokenize and mask\n",
        "def tokenize_and_mask_random(text):\n",
        "  t = tokenizer(text, return_tensors=\"pt\")\n",
        "  random_token_idx = random.randint(1, t[\"input_ids\"].shape[1]-2) # sample random token\n",
        "  original_token = tokenizer.decode(t[\"input_ids\"][0, random_token_idx]) # get the original token\n",
        "  t[\"input_ids\"][0, random_token_idx] = tokenizer.mask_token_id # mask the token\n",
        "  return t, random_token_idx, original_token\n",
        "\n",
        "# define function to get predictions for masked token\n",
        "def get_predictions(tokenized, random_token_idx):\n",
        "  bert_out = bert(**tokenized)\n",
        "  top5 = torch.argsort(bert_out[\"prediction_logits\"], dim=2, descending=True)[:,:,:5] # lets take top5 to answer both 1 and 2\n",
        "  pred_for_mask = top5[0, random_token_idx] # from first input text, select the predictions for masked token\n",
        "  return [tokenizer.decode(t) for t in pred_for_mask]\n",
        "\n",
        "# test with one example\n",
        "tokenized, random_token_idx, original_token = tokenize_and_mask_random(dataset[0][\"text\"])\n",
        "pred_for_mask = get_predictions(tokenized, random_token_idx)\n",
        "\n",
        "print(dataset[0][\"text\"])\n",
        "print(tokenizer.decode(tokenized[\"input_ids\"][0,:]))\n",
        "print(\"Original token:\", original_token)\n",
        "print(\"Predictions:\", pred_for_mask)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enb5_268uFvF",
        "outputId": "933ee6bf-0553-40a7-dc57-e17244b7ac8b"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I rented this movie because it sounded pretty interesting but to my Horror this movie was the worst movie I had ever seen! I read the comment from Gumby-8 and\n",
            "[CLS] I rented this [MASK] because it sounded pretty interesting but to my Horror this movie was the worst movie I had ever seen! I read the comment from Gumby - 8 and [SEP]\n",
            "Original token: movie\n",
            "Predictions: ['movie', 'one', 'film', ',', 'thing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run all\n",
        "# Note: not optimized for speed!\n",
        "\n",
        "top1_acc = 0\n",
        "top5_acc = 0\n",
        "\n",
        "for i,review in enumerate(dataset):\n",
        "  tokenized, random_token_idx, original_token = tokenize_and_mask_random(review[\"text\"])\n",
        "  pred_for_mask = get_predictions(tokenized, random_token_idx)\n",
        "  if pred_for_mask[0]==original_token:\n",
        "    top1_acc+=1\n",
        "  if original_token in pred_for_mask:\n",
        "    top5_acc+=1\n",
        "  if i < 5: # print first 5 examples for visualization\n",
        "    print(i)\n",
        "    print(tokenizer.decode(tokenized[\"input_ids\"][0]))\n",
        "    print(original_token)\n",
        "    print(pred_for_mask)\n",
        "    print()\n",
        "\n",
        "print(\"Top-1 accuracy:\", top1_acc/len(dataset)*100)\n",
        "print(\"Top-5 accuracy:\", top5_acc/len(dataset)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUfRjbmY-LHD",
        "outputId": "cda02540-b5e2-4c9a-95a2-d01a015afbe9"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[CLS] I rented this movie because it sounded pretty interesting but to my Horror this movie was the worst movie [MASK] had ever seen! I read the comment from Gumby - 8 and [SEP]\n",
            "I\n",
            "['I', 'anyone', 'he', 'we', 'they']\n",
            "\n",
            "1\n",
            "[CLS] Moonwalker is absolutely incredible!!!!!!! What [MASK] can I say!? Michael Jackson is the true King of pop, rock and soul!!! Moonwalker has everything! Great story line, [SEP]\n",
            "else\n",
            "['else', 'more', 'exactly', 'words', 'other']\n",
            "\n",
            "2\n",
            "[CLS] To Die For ( 1989 ) was just another d. t. v. feature that made an appearance on cable ad nasuem during the early nineties. The only thing notable [MASK] this feature was the [SEP]\n",
            "about\n",
            "['about', 'in', 'for', 'of', 'from']\n",
            "\n",
            "3\n",
            "[CLS] All Dogs Go To [MASK] is on a par with Watership Down for scary kiddies films. Both were dark and pretty sinister, but at the same time the most mesmerising [SEP]\n",
            "Heaven\n",
            "['Hell', 'School', 'Heaven', 'Sleep', 'War']\n",
            "\n",
            "4\n",
            "[CLS] I got to see this [MASK] at a preview and was dazzled by it. It's not the typical romantic comedy. I can't remember laughing so hard at a film and [SEP]\n",
            "film\n",
            "['film', 'movie', 'one', 'picture', 'comedy']\n",
            "\n",
            "Top-1 accuracy: 56.99999999999999\n",
            "Top-5 accuracy: 79.0\n"
          ]
        }
      ]
    }
  ]
}